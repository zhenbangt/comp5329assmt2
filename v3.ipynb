{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYTGkadIZh4_"
   },
   "source": [
    "# COMP5329 - Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 734,
     "status": "ok",
     "timestamp": 1621175101439,
     "user": {
      "displayName": "Isomorphism__",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCPGQv-x0fGHL4DUlrvt2EuQaICcM6lEXnzGpA=s64",
      "userId": "06837884690357263397"
     },
     "user_tz": -600
    },
    "id": "_HHNTgKRLXK2",
    "outputId": "3c6183f6-fc17-4847-f133-296f04a53d47"
   },
   "outputs": [],
   "source": [
    "# import google\n",
    "import collections\n",
    "import json\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# import torchtext\n",
    "import PIL.Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# MOUNT_PATH = '/content/drive'\n",
    "# DRIVE_PATH = f'{MOUNT_PATH}/My Drive'\n",
    "# PROJECT_PATH = DRIVE_PATH + \"/Assignment 2\"\n",
    "PROJECT_PATH = \"./\"\n",
    "IMG_PATH = f\"{PROJECT_PATH}/data\"\n",
    "TRAIN_CSV_PATH = f\"{PROJECT_PATH}/train.csv\"\n",
    "TEST_CSV_PATH = f\"{PROJECT_PATH}/test.csv\"\n",
    "\n",
    "# google.colab.drive.mount(MOUNT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7c78c3tjbE6d"
   },
   "source": [
    "## Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USEhrYiYHLSx"
   },
   "source": [
    "### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0HX1aBeBjdSP"
   },
   "outputs": [],
   "source": [
    "# df = pandas.read_csv(TRAIN_CSV_PATH, names=range(4), skiprows=1)\n",
    "# classes = df[1].apply(lambda x: list(map(int, x.strip().split()))).to_list()\n",
    "# n_classes = set()\n",
    "# for i in classes:\n",
    "#     n_classes.update(i)\n",
    "# n_clsses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 990,
     "status": "ok",
     "timestamp": 1621175027575,
     "user": {
      "displayName": "Isomorphism__",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCPGQv-x0fGHL4DUlrvt2EuQaICcM6lEXnzGpA=s64",
      "userId": "06837884690357263397"
     },
     "user_tz": -600
    },
    "id": "lutFP6pmayNN"
   },
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "        self.tags = set()\n",
    "        self.df_data = pandas.read_csv(TRAIN_CSV_PATH, names=range(4), skiprows=1)\n",
    "        self.df_data[0] = IMG_PATH + \"/\" + self.df_data[0]\n",
    "        self.df_data[3] = self.df_data[3].fillna(\"\")\n",
    "        self.df_data[2] += self.df_data[3]\n",
    "        self.df_data = self.df_data.drop(3, axis=1)\n",
    "        self.df_data = self.df_data.rename({0: \"image\", 1: \"label\", 2: \"caption\"}, axis=1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image = PIL.Image.open(self.df_data.iloc[idx, 0])\n",
    "        label = self.df_data.iloc[idx, 1]\n",
    "        caption = self.df_data.iloc[idx, 2]\n",
    "\n",
    "        sample = {\"caption\": caption, \"label\": label, \"image\": image}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPE_x_qeGden"
   },
   "source": [
    "### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 514,
     "status": "ok",
     "timestamp": 1621175027576,
     "user": {
      "displayName": "Isomorphism__",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCPGQv-x0fGHL4DUlrvt2EuQaICcM6lEXnzGpA=s64",
      "userId": "06837884690357263397"
     },
     "user_tz": -600
    },
    "id": "oMHDsQa5pbvJ"
   },
   "outputs": [],
   "source": [
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "        self.tags = set()\n",
    "        self.df_data = pandas.read_csv(TEST_CSV_PATH, names=range(3), skiprows=1)\n",
    "        self.df_data[0] = IMG_PATH + \"/\" + self.df_data[0]\n",
    "        self.df_data[2] = self.df_data[2].fillna(\"\")\n",
    "        self.df_data[1] += self.df_data[2]\n",
    "        self.df_data = self.df_data.drop(2, axis=1)\n",
    "        self.df_data = self.df_data.rename({0: \"image\", 1: \"caption\"}, axis=1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image = PIL.Image.open(self.df_data.iloc[idx, 0])\n",
    "        caption = self.df_data.iloc[idx, 1]\n",
    "\n",
    "        sample = {\"caption\": caption, \"image\": image}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_R5B99nfXD3g"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMMUaz1_HJH9"
   },
   "source": [
    "### Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kb-JBmuJwzCI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nltk.download(\"stopwords\")\n",
    "# stopwords = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "# basic_tokenizer = torchtext.data.utils.get_tokenizer(\"basic_english\")\n",
    "# glove = torchtext.vocab.GloVe(name=\"6B\", dim=100)\n",
    "\n",
    "# with open(f\"{PROJECT_PATH}/correct_spelling.json\", \"r\") as f:\n",
    "#     correct_spelling = json.load(f)\n",
    "\n",
    "\n",
    "# def caption_tokenizer(caption):\n",
    "#     caption = re.sub(\"[^a-zA-Z]\", \" \", caption).lower()\n",
    "#     raw_tokens = basic_tokenizer(caption)\n",
    "#     raw_tokens = list(set(raw_tokens).difference(stopwords))\n",
    "#     tokens = []\n",
    "\n",
    "#     for token in raw_tokens:\n",
    "\n",
    "#         if token in correct_spelling:\n",
    "#             corrected_spelling = correct_spelling[token]\n",
    "\n",
    "#             for corrected_token in corrected_spelling.split():\n",
    "#                 if corrected_token in glove.stoi:\n",
    "#                     tokens.append(corrected_token)\n",
    "#         else:\n",
    "#             if token in glove.stoi:\n",
    "#                 tokens.append(token)\n",
    "\n",
    "#     return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7tNqu0vo1Qv5"
   },
   "outputs": [],
   "source": [
    "# train_data = TrainDataset()\n",
    "# test_data = TestDataset()\n",
    "# counter = collections.Counter()\n",
    "\n",
    "# for caption in train_data.df_data[\"caption\"]:\n",
    "#     counter.update(caption_tokenizer(caption))\n",
    "\n",
    "# for caption in test_data.df_data[\"caption\"]:\n",
    "#     counter.update(caption_tokenizer(caption))\n",
    "\n",
    "# vocab = torchtext.vocab.Vocab(counter, vectors=\"glove.6B.100d\", specials=(\"<unk>\", \"<BOS>\", \"<EOS>\", \"<PAD>\"))\n",
    "\n",
    "# del train_data\n",
    "# del test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3scsujfGr18"
   },
   "source": [
    "### Dataset pre-transformations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 781,
     "status": "ok",
     "timestamp": 1621175030901,
     "user": {
      "displayName": "Isomorphism__",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCPGQv-x0fGHL4DUlrvt2EuQaICcM6lEXnzGpA=s64",
      "userId": "06837884690357263397"
     },
     "user_tz": -600
    },
    "id": "zbL0EmlyeNTm"
   },
   "outputs": [],
   "source": [
    "# def vocabularise_caption(dataset, vocab):\n",
    "\n",
    "#     if \"vocabularised_caption\" not in dataset.tags:\n",
    "#         # turns string caption to list of vocab indices\n",
    "#         dataset.df_data[\"caption\"] = dataset.df_data[\"caption\"].apply(\n",
    "#             lambda c: torch.tensor([vocab.stoi[t] for t in caption_tokenizer(c)])\n",
    "#         )\n",
    "\n",
    "#         dataset.tags.add(\"vocabularised_caption\")\n",
    "\n",
    "\n",
    "def one_hot_encode_labels(dataset):\n",
    "    if \"one_hot_encoded_labels\" not in dataset.tags:\n",
    "        dataset.df_data[\"label\"] = dataset.df_data[\"label\"].apply(\n",
    "            lambda l: torch.nn.functional.one_hot(\n",
    "                torch.tensor([int(i) - 1 if int(i) < 12 else int(i) - 2 for i in l.split(\" \")]), 18\n",
    "            )\n",
    "            .sum(axis=0)\n",
    "            .float()\n",
    "        )\n",
    "\n",
    "        dataset.tags.add(\"one_hot_encoded_labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpTCDn6_Vrco"
   },
   "source": [
    "## Modules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCCA7khCHOnG"
   },
   "source": [
    "### Caption embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Ecrmj0tdk78V"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ztan/miniconda3/lib/python3.8/site-packages/torchaudio/backend/utils.py:53: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# class CaptionEmbedding(torch.nn.Module):\n",
    "#     def __init__(self, vocab):\n",
    "#         super(CaptionEmbedding, self).__init__()\n",
    "#         self.word_embedding = torch.nn.Embedding.from_pretrained(vocab.vectors)\n",
    "#         self.linear1 = torch.nn.Linear(vocab.vectors.shape[1], 18)\n",
    "#         self.lrelu1 = torch.nn.LeakyReLU()\n",
    "#         self.linear2 = torch.nn.Linear(18, 1)\n",
    "#         self.lrelu2 = torch.nn.LeakyReLU()\n",
    "#         self.lrelu3 = torch.nn.LeakyReLU()\n",
    "\n",
    "#     def forward(self, captions):\n",
    "#         def _embed_caption(c):\n",
    "#             c = c.to(DEVICE)\n",
    "#             c = self.word_embedding(c)\n",
    "#             word_importance = self.linear1(c)\n",
    "#             word_importance = self.lrelu1(word_importance)\n",
    "#             word_importance = self.linear2(word_importance)\n",
    "#             word_importance = self.lrelu2(word_importance)\n",
    "#             return self.lrelu3(c.T @ word_importance).view(-1)\n",
    "\n",
    "#         return torch.stack([*map(lambda c: _embed_caption(c), captions)])\n",
    "\n",
    "from transformers import AutoFeatureExtractor, AutoModel, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\")\n",
    "lang_model = AutoModel.from_pretrained(\"prajjwal1/bert-tiny\")\n",
    "lang_model.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vial1naJBNC7"
   },
   "source": [
    "### Pretrained model surgery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6hUrTmdVBj0Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "# class Surgery(torch.nn.Module):\n",
    "#     def __init__(self, name, selection, training_disabled=True):\n",
    "#         super(Surgery, self).__init__()\n",
    "#         model = getattr(torchvision.models, name)(pretrained=True)\n",
    "#         children = list(model.children())\n",
    "\n",
    "#         self.sequential = torch.nn.Sequential(*[children[i] for i in selection])\n",
    "\n",
    "#         if training_disabled:\n",
    "#             for param in self.sequential.parameters():\n",
    "#                 param.requires_grad = False\n",
    "\n",
    "#     def forward(self, x):\n",
    "\n",
    "#         return self.sequential(x)\n",
    "\n",
    "\n",
    "# def surgery_info(name):\n",
    "#     model = getattr(torchvision.models, name)()\n",
    "\n",
    "#     for idx, child in enumerate(model.children()):\n",
    "#         print(f\"Accessible at {idx}:\\n{child}\\n\")\n",
    "\n",
    "# !pip install efficientnet_pytorch\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19}\n",
    "features = EfficientNet.from_pretrained(\"efficientnet-b0\")\n",
    "\n",
    "require_grad = False\n",
    "for name, param in features.named_parameters():\n",
    "    #     print(name.split(\".\")[1])\n",
    "    if name.split(\".\")[1] == \"14\":  # required grad for last 2 blocks\n",
    "        require_grad = True\n",
    "    param.require_grad = require_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v44fbNqCOtv9"
   },
   "source": [
    "### Combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "aUtVf9QdOxnN"
   },
   "outputs": [],
   "source": [
    "NUM_ClASSES = 18\n",
    "import math\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Combined_Model(torch.nn.Module):\n",
    "    def __init__(self, visual_features, lang_model):\n",
    "        super().__init__()\n",
    "        self.visual_features = visual_features\n",
    "        self.lang_model = lang_model\n",
    "        self.proj = nn.Linear(1000, 128)  # (feature.shape, hidden.shape)\n",
    "        self.scale = math.sqrt(128)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.out = nn.Linear(256, NUM_ClASSES)\n",
    "\n",
    "    def forward(self, images, input_ids, attention_mask):  # requires tokenized captions\n",
    "        images = self.visual_features(images)\n",
    "        images = self.proj(images)\n",
    "\n",
    "        lang_outs = self.lang_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden = lang_outs[\"last_hidden_state\"]\n",
    "\n",
    "        attention_weights = (\n",
    "            torch.bmm(hidden, images.unsqueeze(-1)).squeeze(-1) / self.scale\n",
    "        )  # (batch, seq_len, 1)\n",
    "        attention_out = torch.bmm(attention_weights.unsqueeze(1), hidden).squeeze(1)\n",
    "\n",
    "        return self.out(self.activation(torch.cat([images, attention_out], dim=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "aUtVf9QdOxnN"
   },
   "outputs": [],
   "source": [
    "# class Combined(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Combined, self).__init__()\n",
    "#         # self.image_embedder = Surgery('vgg16', [0])\n",
    "#         self.image_embedder = features\n",
    "#         # self.caption_embedder = CaptionEmbedding(vocab)\n",
    "\n",
    "#         # self.linear1 = torch.nn.Linear(2148, 256)\n",
    "#         self.linear1 = torch.nn.Linear(1000, 256)\n",
    "#         self.lrelu1 = torch.nn.LeakyReLU()\n",
    "#         # self.linear2 = torch.nn.Linear(256, 18)\n",
    "#         # self.lrelu2 = torch.nn.LeakyReLU()\n",
    "\n",
    "#         self.heads = nn.ModuleList([nn.Linear(256, 1) for i in range(NUM_ClASSES)])\n",
    "\n",
    "#     def forward(self, images, captions):\n",
    "#         image_embeddings = self.image_embedder(images)\n",
    "#         # image_embeddings = image_embeddings.view(images.shape[0], -1) #???\n",
    "\n",
    "#         # caption_embeddings = self.caption_embedder(captions)\n",
    "#         # caption_embeddings = caption_embeddings.view(caption_embeddings.shape[0], -1)\n",
    "\n",
    "#         # combined_embedding = torch.cat([image_embeddings, caption_embeddings], 1)\n",
    "#         # y = self.linear1(combined_embedding)\n",
    "\n",
    "#         y = self.linear1(image_embeddings)\n",
    "#         y = self.lrelu1(y)\n",
    "\n",
    "#         outs = []\n",
    "#         for i in range(NUM_ClASSES):\n",
    "#             outs.append(self.heads[i](y))\n",
    "\n",
    "#         return torch.cat(outs, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srZFInwa78_j"
   },
   "source": [
    "## Transforms and training support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 772,
     "status": "ok",
     "timestamp": 1621175053522,
     "user": {
      "displayName": "Isomorphism__",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCPGQv-x0fGHL4DUlrvt2EuQaICcM6lEXnzGpA=s64",
      "userId": "06837884690357263397"
     },
     "user_tz": -600
    },
    "id": "MvOT-Plt78Zp"
   },
   "outputs": [],
   "source": [
    "class FieldTransform(object):\n",
    "    def __init__(self, field, transform):\n",
    "        self.field = field\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sample[self.field] = self.transform(sample[self.field])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZHM_qQiQniU"
   },
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 771,
     "status": "ok",
     "timestamp": 1621175053523,
     "user": {
      "displayName": "Isomorphism__",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCPGQv-x0fGHL4DUlrvt2EuQaICcM6lEXnzGpA=s64",
      "userId": "06837884690357263397"
     },
     "user_tz": -600
    },
    "id": "oPqavf7wWfiB"
   },
   "outputs": [],
   "source": [
    "def train_collate_fn(X):\n",
    "    # convert [{key: val, ...}, ...]\n",
    "    # to [key: [val, ...],  ...}\n",
    "    X = {k: [v[k] for v in X] for k in X[0]}\n",
    "    X[\"label\"] = torch.stack(X[\"label\"])\n",
    "    X[\"image\"] = torch.stack(X[\"image\"])\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        #   FieldTransform('image', torchvision.transforms.Resize((64, 64))),\n",
    "        #   FieldTransform('image', torchvision.transforms.CenterCrop(64)),\n",
    "        FieldTransform(\"image\", torchvision.transforms.Resize((224, 224))),\n",
    "        FieldTransform(\"image\", torchvision.transforms.ToTensor()),\n",
    "        FieldTransform(\"image\", normalize),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 2421,
     "status": "ok",
     "timestamp": 1621175110701,
     "user": {
      "displayName": "Isomorphism__",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCPGQv-x0fGHL4DUlrvt2EuQaICcM6lEXnzGpA=s64",
      "userId": "06837884690357263397"
     },
     "user_tz": -600
    },
    "id": "o_5acvhCWjSn"
   },
   "outputs": [],
   "source": [
    "train_data = TrainDataset(transform=transforms)\n",
    "# vocabularise_caption(train_data, vocab)\n",
    "one_hot_encode_labels(train_data)\n",
    "\n",
    "# model = Combined().to(DEVICE)\n",
    "model = Combined_Model(features, lang_model).to(device)\n",
    "optim = torch.optim.Adam(model.parameters(),lr = 0.0001)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# train_data.__len__() == 30000\n",
    "trainds, valds = torch.utils.data.random_split(train_data, [27000, 3000])\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    trainds, batch_size=64, shuffle=True, collate_fn=train_collate_fn, num_workers=24,\n",
    ")\n",
    "\n",
    "val_dl = torch.utils.data.DataLoader(\n",
    "    valds, batch_size=8, shuffle=False, collate_fn=train_collate_fn, num_workers=24\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iuhLuCQxQnR1",
    "outputId": "bde8bc1d-7820-460e-8d89-e78e8af216d4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:13<00:00,  5.76it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 0.22427690230415895, Val Loss: 0.12526776771247386, F1: 0.7864962962962964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:12<00:00,  5.85it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 0.1131653900112586, Val Loss: 0.10221032429983219, F1: 0.8331309523809522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:11<00:00,  5.88it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train Loss: 0.09509854064592253, Val Loss: 0.09455411384006342, F1: 0.8480767195767197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:10<00:00,  5.98it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train Loss: 0.08483526234236939, Val Loss: 0.08992218871042132, F1: 0.861554761904762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:11<00:00,  5.87it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train Loss: 0.07662882341592797, Val Loss: 0.08635167007272442, F1: 0.8667267195767197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:10<00:00,  6.02it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train Loss: 0.07057392773311144, Val Loss: 0.08404278780147434, F1: 0.8681457671957672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:09<00:00,  6.06it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train Loss: 0.0646725934687384, Val Loss: 0.08311533896438777, F1: 0.8723773689273691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:09<00:00,  6.07it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Train Loss: 0.0588071371177079, Val Loss: 0.08415715181455016, F1: 0.8749452380952382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:12<00:00,  5.81it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Train Loss: 0.05412490576752837, Val Loss: 0.08620182118875284, F1: 0.8789531746031746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:14<00:00,  5.66it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Train Loss: 0.048907259399715755, Val Loss: 0.09145594121453662, F1: 0.8737526455026454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:15<00:00,  5.57it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train Loss: 0.04360284597140635, Val Loss: 0.09222581857210026, F1: 0.8726945406445407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:12<00:00,  5.83it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Train Loss: 0.03874325933888272, Val Loss: 0.09946337987730901, F1: 0.872916354016354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:12<00:00,  5.82it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Train Loss: 0.03416787921914487, Val Loss: 0.10385541129702082, F1: 0.8728761183261182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:12<00:00,  5.81it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Train Loss: 0.02976147650401174, Val Loss: 0.10992494471340129, F1: 0.8724391534391535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:09<00:00,  6.05it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Train Loss: 0.026196358921844954, Val Loss: 0.12005773759734197, F1: 0.8726223184223184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:10<00:00,  5.99it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Train Loss: 0.023428243818865, Val Loss: 0.11936209173717846, F1: 0.8696636123136122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:12<00:00,  5.81it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Train Loss: 0.020133718538155418, Val Loss: 0.13438180018123239, F1: 0.8727236411736411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:13<00:00,  5.75it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Train Loss: 0.018348399080750998, Val Loss: 0.1355632109933067, F1: 0.869273088023088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:11<00:00,  5.91it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Train Loss: 0.016556678688533215, Val Loss: 0.13548857188162705, F1: 0.8683131553631553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:13<00:00,  5.75it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Train Loss: 0.014070803247131761, Val Loss: 0.15062384279700927, F1: 0.8723885521885523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:12<00:00,  5.80it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Train Loss: 0.013033692448585342, Val Loss: 0.15661603413498962, F1: 0.87152506012506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:12<00:00,  5.83it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Train Loss: 0.011878777906945267, Val Loss: 0.1648251425541627, F1: 0.8715428811928811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:12<00:00,  5.78it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Train Loss: 0.010526084644561059, Val Loss: 0.17017447080144968, F1: 0.8698165223665224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:13<00:00,  5.78it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Train Loss: 0.010215512394929366, Val Loss: 0.17221969422104302, F1: 0.8711769841269841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:13<00:00,  5.77it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Train Loss: 0.00871878245876334, Val Loss: 0.1781954098175047, F1: 0.8728740740740741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:23<00:00,  5.06it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Train Loss: 0.008612048817865807, Val Loss: 0.18048335141444113, F1: 0.870763011063011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:13<00:00,  5.74it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Train Loss: 0.007925413751569731, Val Loss: 0.18820414627275509, F1: 0.8711962962962961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:15<00:00,  5.58it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Train Loss: 0.007264070913953689, Val Loss: 0.18933897789897552, F1: 0.8713803511303513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:14<00:00,  5.69it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Train Loss: 0.006933129749534502, Val Loss: 0.19522928214371496, F1: 0.8724820586820586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:12<00:00,  5.84it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Train Loss: 0.006368257390526653, Val Loss: 0.1958871137296422, F1: 0.8705836940836941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:14<00:00,  5.64it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Train Loss: 0.00633046254780479, Val Loss: 0.19528370608649373, F1: 0.8702512746512745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:13<00:00,  5.78it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31, Train Loss: 0.006027726213968032, Val Loss: 0.211394925245307, F1: 0.875670731120731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:12<00:00,  5.86it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, Train Loss: 0.005599334182618274, Val Loss: 0.1933275813755851, F1: 0.8731588263588262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:09<00:00,  6.08it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33, Train Loss: 0.0054251866053965855, Val Loss: 0.22523601199168963, F1: 0.873152477152477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [01:12<00:00,  5.84it/s]\n",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, Train Loss: 0.005229638509771795, Val Loss: 0.21473534053738694, F1: 0.8720251322751322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 385/422 [01:06<00:05,  6.20it/s]Process Process-1688:\n",
      "Process Process-1689:\n",
      "Process Process-1687:\n",
      "Process Process-1685:\n",
      "Process Process-1693:\n",
      "Process Process-1694:\n",
      "Process Process-1692:\n",
      "Process Process-1682:\n",
      "Process Process-1690:\n",
      "Process Process-1691:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7efcc3f3a1f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/popen_fork.py\", line 44, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      " 91%|█████████ | 385/422 [01:07<00:06,  5.67it/s]  File \"/home/ztan/miniconda3/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-15-9680e2e8347f>\", line 30, in <module>\n",
      "    scaler.step(optim)\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py\", line 320, in step\n",
      "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py\", line 320, in <genexpr>\n",
      "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/posixpath.py\", line 391, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/posixpath.py\", line 425, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/ztan/miniconda3/lib/python3.8/posixpath.py\", line 167, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-9680e2e8347f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2060\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2061\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2063\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2064\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "val_f1 = []\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "for epoch in range(50):\n",
    "    train_loss = []\n",
    "    train_outs = []\n",
    "    train_lables = []\n",
    "\n",
    "    model.train()\n",
    "    for i, batch in enumerate(tqdm(train_dl)):\n",
    "        optim.zero_grad()\n",
    "        captions = batch[\"caption\"]\n",
    "        images = batch[\"image\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            captions, return_tensors=\"pt\", padding=True, truncation=True, max_length=40\n",
    "        )\n",
    "        input_ids = inputs[\"input_ids\"].to(device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            predictions = model(images, input_ids, attention_mask)\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "        #\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optim)\n",
    "        scaler.update()\n",
    "#         train_loss.append(scaled_loss.item())\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "    val_loss = []\n",
    "    val_outs = []\n",
    "    val_labels = []\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    for i, batch in enumerate(val_dl):\n",
    "\n",
    "        captions = batch[\"caption\"]\n",
    "        images = batch[\"image\"].to(DEVICE)\n",
    "        labels = batch[\"label\"].to(DEVICE)\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            captions, return_tensors=\"pt\", padding=True, truncation=True, max_length=40\n",
    "        )\n",
    "        input_ids = inputs[\"input_ids\"].to(device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "        \n",
    "        #         predictions = model(images, captions)\n",
    "        predictions = model(images, input_ids, attention_mask)\n",
    "        loss = criterion(predictions, labels)\n",
    "        val_loss.append(loss.item())\n",
    "        val_outs.append(predictions.detach().cpu().numpy())\n",
    "        val_labels.append(labels.detach().cpu().numpy())\n",
    "    val_labels = np.vstack(val_labels)\n",
    "    val_outs = np.vstack(val_outs)\n",
    "    f1 = f1_score(y_true=val_labels, y_pred=1 * (val_outs > 0), average=\"samples\")\n",
    "    if len(val_f1) == 0 or f1 > min(val_f1):\n",
    "        torch.save(model, \"test_model.pt\")\n",
    "    val_f1.append(f1)\n",
    "    print(\n",
    "        f\"Epoch: {epoch}, Train Loss: {np.mean(train_loss)}, Val Loss: {np.mean(val_loss)}, F1: {f1}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopper for run all\n",
    "raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.load(\"test_model.pt\")\n",
    "\n",
    "def test_collate_fn(X):\n",
    "    # convert [{key: val, ...}, ...]\n",
    "    # to [key: [val, ...],  ...}\n",
    "    X = {k: [v[k] for v in X] for k in X[0]}\n",
    "    X[\"image\"] = torch.stack(X[\"image\"])\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "test_data = TestDataset(transform=transforms)\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=16, shuffle=False, collate_fn=test_collate_fn, num_workers=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions\n",
    "model.eval()\n",
    "test_preds = []\n",
    "for i, batch in enumerate(test_dl):\n",
    "    captions = batch[\"caption\"]\n",
    "    images = batch[\"image\"].to(DEVICE)\n",
    "\n",
    "    predictions = model(images, input_ids, attention_mask)\n",
    "    test_preds.append(predictions.detach().cpu().numpy())\n",
    "\n",
    "test_preds = np.vstack(test_preds)\n",
    "\n",
    "def out_logits_to_preds(logits):\n",
    "    labels = []\n",
    "    logits = logits > 0\n",
    "    lables_available = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19])\n",
    "    for i in range(logits.shape[0]):\n",
    "        labels.append(list(lables_available[logits[i]]))\n",
    "    return labels\n",
    "\n",
    "\n",
    "# lables_available[(test_preds[:10] > 0)]\n",
    "# {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19}\n",
    "test_labels = out_logits_to_preds(test_preds)\n",
    "\n",
    "df_test = pd.read_csv(TEST_CSV_PATH, names=range(3), skiprows=1)\n",
    "test_labels_str = [\" \".join([str(i) for i in labels]) for labels in test_labels]\n",
    "df_test[\"Labels\"] = test_labels_str\n",
    "df_test.rename({0: \"ImageID\"}, axis=1, inplace=True)\n",
    "\n",
    "df_test[[\"ImageID\", \"Labels\"]].to_csv(\"test_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7EHVDCtd-9r"
   },
   "source": [
    "### Just label model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdbXbYNQvsXg"
   },
   "outputs": [],
   "source": [
    "def weight1(dataset):\n",
    "    one_hot_encode_labels(dataset)\n",
    "    labels = torch.stack(dataset.df_data[\"label\"].to_list())\n",
    "    counts = labels.sum(axis=0)\n",
    "    weights = labels @ (1 / counts)\n",
    "    return weights / weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FP8n7k9_v8EM"
   },
   "outputs": [],
   "source": [
    "def weight2(dataset):\n",
    "    one_hot_encode_labels(dataset)\n",
    "    labels = torch.stack(dataset.df_data[\"label\"].to_list())\n",
    "    dataset.df_data = dataset.df_data[(labels.sum(axis=1) == 1).numpy()]\n",
    "    dataset.df_data = dataset.df_data.reset_index(drop=True)\n",
    "    labels = torch.stack(dataset.df_data[\"label\"].to_list())\n",
    "    counts = labels.sum(axis=0)\n",
    "    weights = labels @ (1 / counts)\n",
    "    return weights / weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3bBQD-di5UUB"
   },
   "outputs": [],
   "source": [
    "def weight3(dataset):\n",
    "    one_hot_encode_labels(dataset)\n",
    "    labels = torch.stack(dataset.df_data[\"label\"].to_list())\n",
    "    sums = torch.sum(labels * 2 ** torch.arange(18), axis=1)\n",
    "    uniques, counts = torch.unique(sums, return_counts=True)\n",
    "    p = 1 / counts\n",
    "    w = torch.zeros_like(sums)\n",
    "\n",
    "    for i in range(len(uniques)):\n",
    "        w[sums == uniques[i]] = p[i]\n",
    "\n",
    "    return w / w.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eu-Ub6m5fOon"
   },
   "outputs": [],
   "source": [
    "class CaptionEmbedding(torch.nn.Module):\n",
    "    def __init__(self, vocab):\n",
    "        super(CaptionEmbedding, self).__init__()\n",
    "        self.word_embedding = torch.nn.Embedding.from_pretrained(vocab.vectors)\n",
    "        self.linear1 = torch.nn.Linear(vocab.vectors.shape[1], 54)\n",
    "        self.linear2 = torch.nn.Linear(54, 18)\n",
    "        self.linear3 = torch.nn.Linear(18, 1)\n",
    "\n",
    "    def forward(self, captions):\n",
    "        def _embed_caption(c):\n",
    "            c = c.to(DEVICE)\n",
    "            c = self.word_embedding(c)\n",
    "            word_importance = torch.nn.functional.leaky_relu(self.linear1(c))\n",
    "            word_importance = torch.nn.functional.leaky_relu(self.linear2(word_importance))\n",
    "            word_importance = torch.nn.functional.leaky_relu(self.linear3(word_importance))\n",
    "            return (c.T @ word_importance).view(-1)\n",
    "\n",
    "        return torch.stack([*map(lambda c: _embed_caption(c), captions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XRVrejxCeJTx"
   },
   "outputs": [],
   "source": [
    "class AlexJustLabelModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexJustLabelModel, self).__init__()\n",
    "        self.caption_embedder = CaptionEmbedding(vocab)\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(100, 54)\n",
    "        self.linear2 = torch.nn.Linear(54, 36)\n",
    "        self.linear3 = torch.nn.Linear(100, 18)\n",
    "        self.dropout = torch.nn.Dropout(0.05)\n",
    "\n",
    "    def forward(self, captions):\n",
    "        caption_embeddings = self.caption_embedder(captions)\n",
    "        y = self.dropout(caption_embeddings)\n",
    "        # y = torch.nn.functional.leaky_relu(self.linear1(y))\n",
    "        # y = torch.nn.functional.leaky_relu(self.linear2(y))\n",
    "        y = self.linear3(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cAK-vkLKTOex"
   },
   "outputs": [],
   "source": [
    "def train_collate_fn(X):\n",
    "    # convert [{key: val, ...}, ...]\n",
    "    # to [key: [val, ...],  ...}\n",
    "    X = {k: [v[k] for v in X] for k in X[0]}\n",
    "    X[\"label\"] = torch.stack(X[\"label\"])\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "train_data = TrainDataset(transform=transforms)\n",
    "vocabularise_caption(train_data, vocab)\n",
    "one_hot_encode_labels(train_data)\n",
    "weights = weight2(train_data)\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=32, num_workers=2, collate_fn=train_collate_fn, sampler=sampler\n",
    ")\n",
    "\n",
    "model = AlexJustLabelModel().to(DEVICE)\n",
    "model.train()\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "for e in range(10):\n",
    "    print(f\"EPOCH {e}\")\n",
    "\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        optim.zero_grad()\n",
    "        captions = batch[\"caption\"]\n",
    "        labels = batch[\"label\"].to(DEVICE)\n",
    "\n",
    "        predictions = model(captions)\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1kYBH0Bkns11",
    "outputId": "0a04e4dc-5b33-4894-9556-53efb57c75dc"
   },
   "outputs": [],
   "source": [
    "def train_collate_fn(X):\n",
    "    # convert [{key: val, ...}, ...]\n",
    "    # to [key: [val, ...],  ...}\n",
    "    X = {k: [v[k] for v in X] for k in X[0]}\n",
    "    X[\"label\"] = torch.stack(X[\"label\"])\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "train_data = TrainDataset(transform=transforms)\n",
    "vocabularise_caption(train_data, vocab)\n",
    "one_hot_encode_labels(train_data)\n",
    "weights = weight3(train_data)\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=32, num_workers=2, collate_fn=train_collate_fn, sampler=sampler\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for i, batch in enumerate(dataloader):\n",
    "\n",
    "    captions = batch[\"caption\"]\n",
    "    labels = batch[\"label\"].to(DEVICE)\n",
    "\n",
    "    predictions = torch.nn.functional.sigmoid(model(captions))\n",
    "\n",
    "    for p in range(len(predictions)):\n",
    "        print(labels[p])\n",
    "        print(predictions[p])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YJhDG-sgnq0x",
    "outputId": "f66c8bf7-7b7e-4a2e-decf-0353618b27e2"
   },
   "outputs": [],
   "source": [
    "def train_collate_fn(X):\n",
    "    # convert [{key: val, ...}, ...]\n",
    "    # to [key: [val, ...],  ...}\n",
    "    X = {k: [v[k] for v in X] for k in X[0]}\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "train_data = TestDataset(transform=transforms)\n",
    "vocabularise_caption(train_data, vocab)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=32, num_workers=2, collate_fn=train_collate_fn\n",
    ")\n",
    "\n",
    "for e in range(10):\n",
    "    print(f\"EPOCH {e}\")\n",
    "\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        captions = batch[\"caption\"]\n",
    "        predictions = model(captions)\n",
    "        for p in torch.nn.functional.sigmoid(predictions):\n",
    "            print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzHrVSC3b70L"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4U1dZzn4Hakq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KFGPyIyxTaT9",
    "outputId": "6c1fccf0-4b11-49c0-f45d-6a5c94c749e0"
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import sklearn.preprocessing\n",
    "\n",
    "mlb = sklearn.preprocessing.MultiLabelBinarizer([1, 2, 3, 4, 5])\n",
    "y_true = mlb.fit_transform([{1, 2}, {3}])\n",
    "y_pred = mlb.fit_transform([{1, 3}, {3}])\n",
    "sklearn.metrics.f1_score(y_pred, y_true, average=\"samples\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "COMP5329_Assignment_2_v3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "105bdd467ce44751b3020eddd3d4c791": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37766d0f97754f21a9b78ec7c2c9b266": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b5faf89e145490b8df3c5a0974a30e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37766d0f97754f21a9b78ec7c2c9b266",
      "max": 21388428,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a0e1d4db2eb74c24887d9b9d63e36a2a",
      "value": 21388428
     }
    },
    "6c592ed619724f1997199bf45b9727e7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "775c2d8bc3824da89165a6baf24327c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3b5faf89e145490b8df3c5a0974a30e0",
       "IPY_MODEL_fbc0ba310f384411ad658bc8ceee5607"
      ],
      "layout": "IPY_MODEL_6c592ed619724f1997199bf45b9727e7"
     }
    },
    "9929ab1374f74db7addc12be1eaa6a29": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0e1d4db2eb74c24887d9b9d63e36a2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fbc0ba310f384411ad658bc8ceee5607": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_105bdd467ce44751b3020eddd3d4c791",
      "placeholder": "​",
      "style": "IPY_MODEL_9929ab1374f74db7addc12be1eaa6a29",
      "value": " 20.4M/20.4M [00:00&lt;00:00, 70.0MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
