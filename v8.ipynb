{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYTGkadIZh4_"
   },
   "source": [
    "# COMP5329 - Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 734,
     "status": "ok",
     "timestamp": 1621175101439,
     "user": {
      "displayName": "Isomorphism__",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCPGQv-x0fGHL4DUlrvt2EuQaICcM6lEXnzGpA=s64",
      "userId": "06837884690357263397"
     },
     "user_tz": -600
    },
    "id": "_HHNTgKRLXK2",
    "outputId": "3c6183f6-fc17-4847-f133-296f04a53d47"
   },
   "outputs": [],
   "source": [
    "# import google\n",
    "import collections\n",
    "import json\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# import torchtext\n",
    "import PIL.Image\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# MOUNT_PATH = '/content/drive'\n",
    "# DRIVE_PATH = f'{MOUNT_PATH}/My Drive'\n",
    "# PROJECT_PATH = DRIVE_PATH + \"/Assignment 2\"\n",
    "PROJECT_PATH = \"./\"\n",
    "IMG_PATH = f\"{PROJECT_PATH}/data\"\n",
    "TRAIN_CSV_PATH = f\"{PROJECT_PATH}/train.csv\"\n",
    "TEST_CSV_PATH = f\"{PROJECT_PATH}/test.csv\"\n",
    "\n",
    "# google.colab.drive.mount(MOUNT_PATH)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['efficientnet_b0',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b1_pruned',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b2_pruned',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b3_pruned',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_el',\n",
       " 'efficientnet_el_pruned',\n",
       " 'efficientnet_em',\n",
       " 'efficientnet_es',\n",
       " 'efficientnet_es_pruned',\n",
       " 'efficientnet_lite0',\n",
       " 'efficientnetv2_rw_s',\n",
       " 'tf_efficientnet_b0',\n",
       " 'tf_efficientnet_b0_ap',\n",
       " 'tf_efficientnet_b0_ns',\n",
       " 'tf_efficientnet_b1',\n",
       " 'tf_efficientnet_b1_ap',\n",
       " 'tf_efficientnet_b1_ns',\n",
       " 'tf_efficientnet_b2',\n",
       " 'tf_efficientnet_b2_ap',\n",
       " 'tf_efficientnet_b2_ns',\n",
       " 'tf_efficientnet_b3',\n",
       " 'tf_efficientnet_b3_ap',\n",
       " 'tf_efficientnet_b3_ns',\n",
       " 'tf_efficientnet_b4',\n",
       " 'tf_efficientnet_b4_ap',\n",
       " 'tf_efficientnet_b4_ns',\n",
       " 'tf_efficientnet_b5',\n",
       " 'tf_efficientnet_b5_ap',\n",
       " 'tf_efficientnet_b5_ns',\n",
       " 'tf_efficientnet_b6',\n",
       " 'tf_efficientnet_b6_ap',\n",
       " 'tf_efficientnet_b6_ns',\n",
       " 'tf_efficientnet_b7',\n",
       " 'tf_efficientnet_b7_ap',\n",
       " 'tf_efficientnet_b7_ns',\n",
       " 'tf_efficientnet_b8',\n",
       " 'tf_efficientnet_b8_ap',\n",
       " 'tf_efficientnet_cc_b0_4e',\n",
       " 'tf_efficientnet_cc_b0_8e',\n",
       " 'tf_efficientnet_cc_b1_8e',\n",
       " 'tf_efficientnet_el',\n",
       " 'tf_efficientnet_em',\n",
       " 'tf_efficientnet_es',\n",
       " 'tf_efficientnet_l2_ns',\n",
       " 'tf_efficientnet_l2_ns_475',\n",
       " 'tf_efficientnet_lite0',\n",
       " 'tf_efficientnet_lite1',\n",
       " 'tf_efficientnet_lite2',\n",
       " 'tf_efficientnet_lite3',\n",
       " 'tf_efficientnet_lite4',\n",
       " 'tf_efficientnetv2_b0',\n",
       " 'tf_efficientnetv2_b1',\n",
       " 'tf_efficientnetv2_b2',\n",
       " 'tf_efficientnetv2_b3',\n",
       " 'tf_efficientnetv2_l',\n",
       " 'tf_efficientnetv2_l_in21ft1k',\n",
       " 'tf_efficientnetv2_l_in21k',\n",
       " 'tf_efficientnetv2_m',\n",
       " 'tf_efficientnetv2_m_in21ft1k',\n",
       " 'tf_efficientnetv2_m_in21k',\n",
       " 'tf_efficientnetv2_s',\n",
       " 'tf_efficientnetv2_s_in21ft1k',\n",
       " 'tf_efficientnetv2_s_in21k']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models(\n",
    "    \"*efficient*\", pretrained=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from effdet import create_model\n",
    "\n",
    "# model = create_model(\"tf_efficientdet_d0\", bench_task=\"predict\", num_classes=18, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "img = torch.randn(1, 3, 224, 224)\n",
    "model = timm.create_model(\"tf_efficientnetv2_b1\", pretrained=True, features_only=True)\n",
    "# img = torch.randn(1, 3, 256, 256)\n",
    "# summary(model, input_data=img, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200704\n",
      "100352\n",
      "37632\n",
      "21952\n",
      "9408\n"
     ]
    }
   ],
   "source": [
    "for x in model(img):\n",
    "    print(np.prod(list(x.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9408\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(\"tresnet_m\", pretrained=True, num_classes=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = torch.randn(1, 3, 224, 224)\n",
    "model(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "TResNet                                            --                        --\n",
       "├─Sequential: 1-1                                  [1, 2048, 7, 7]           --\n",
       "│    └─SpaceToDepthModule: 2-1                     [1, 48, 56, 56]           --\n",
       "│    └─Sequential: 2-2                             [1, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-1                            [1, 64, 56, 56]           27,648\n",
       "│    │    └─InplaceAbn: 3-2                        [1, 64, 56, 56]           128\n",
       "│    └─Sequential: 2-3                             [1, 64, 56, 56]           --\n",
       "│    │    └─BasicBlock: 3-3                        [1, 64, 56, 56]           82,304\n",
       "│    │    └─BasicBlock: 3-4                        [1, 64, 56, 56]           82,304\n",
       "│    │    └─BasicBlock: 3-5                        [1, 64, 56, 56]           82,304\n",
       "│    └─Sequential: 2-4                             [1, 128, 28, 28]          --\n",
       "│    │    └─BasicBlock: 3-6                        [1, 128, 28, 28]          246,720\n",
       "│    │    └─BasicBlock: 3-7                        [1, 128, 28, 28]          312,000\n",
       "│    │    └─BasicBlock: 3-8                        [1, 128, 28, 28]          312,000\n",
       "│    │    └─BasicBlock: 3-9                        [1, 128, 28, 28]          312,000\n",
       "│    └─Sequential: 2-5                             [1, 1024, 14, 14]         --\n",
       "│    │    └─Bottleneck: 3-10                       [1, 1024, 14, 14]         1,086,848\n",
       "│    │    └─Bottleneck: 3-11                       [1, 1024, 14, 14]         1,183,104\n",
       "│    │    └─Bottleneck: 3-12                       [1, 1024, 14, 14]         1,183,104\n",
       "│    │    └─Bottleneck: 3-13                       [1, 1024, 14, 14]         1,183,104\n",
       "│    │    └─Bottleneck: 3-14                       [1, 1024, 14, 14]         1,183,104\n",
       "│    │    └─Bottleneck: 3-15                       [1, 1024, 14, 14]         1,183,104\n",
       "│    │    └─Bottleneck: 3-16                       [1, 1024, 14, 14]         1,183,104\n",
       "│    │    └─Bottleneck: 3-17                       [1, 1024, 14, 14]         1,183,104\n",
       "│    │    └─Bottleneck: 3-18                       [1, 1024, 14, 14]         1,183,104\n",
       "│    │    └─Bottleneck: 3-19                       [1, 1024, 14, 14]         1,183,104\n",
       "│    │    └─Bottleneck: 3-20                       [1, 1024, 14, 14]         1,183,104\n",
       "│    └─Sequential: 2-6                             [1, 2048, 7, 7]           --\n",
       "│    │    └─Bottleneck: 3-21                       [1, 2048, 7, 7]           6,039,552\n",
       "│    │    └─Bottleneck: 3-22                       [1, 2048, 7, 7]           4,462,592\n",
       "│    │    └─Bottleneck: 3-23                       [1, 2048, 7, 7]           4,462,592\n",
       "├─ClassifierHead: 1-2                              [1, 2048]                 --\n",
       "│    └─SelectAdaptivePool2d: 2-7                   [1, 2048]                 --\n",
       "│    │    └─FastAdaptiveAvgPool2d: 3-24            [1, 2048]                 --\n",
       "│    └─Identity: 2-8                               [1, 2048]                 --\n",
       "====================================================================================================\n",
       "Total params: 29,340,032\n",
       "Trainable params: 29,340,032\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 5.73\n",
       "====================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 114.04\n",
       "Params size (MB): 117.36\n",
       "Estimated Total Size (MB): 232.01\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model, input_data=img, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body\n",
      "head\n"
     ]
    }
   ],
   "source": [
    "for name, child in model.named_children():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "Sequential                                    --                        --\n",
       "├─SpaceToDepthModule: 1-1                     [1, 48, 56, 56]           --\n",
       "├─Sequential: 1-2                             [1, 64, 56, 56]           --\n",
       "│    └─Conv2d: 2-1                            [1, 64, 56, 56]           27,648\n",
       "│    └─InplaceAbn: 2-2                        [1, 64, 56, 56]           128\n",
       "├─Sequential: 1-3                             [1, 64, 56, 56]           --\n",
       "│    └─BasicBlock: 2-3                        [1, 64, 56, 56]           --\n",
       "│    │    └─Sequential: 3-1                   [1, 64, 56, 56]           36,992\n",
       "│    │    └─Sequential: 3-2                   [1, 64, 56, 56]           36,992\n",
       "│    │    └─SEModule: 3-3                     [1, 64, 56, 56]           8,320\n",
       "│    │    └─ReLU: 3-4                         [1, 64, 56, 56]           --\n",
       "│    └─BasicBlock: 2-4                        [1, 64, 56, 56]           --\n",
       "│    │    └─Sequential: 3-5                   [1, 64, 56, 56]           36,992\n",
       "│    │    └─Sequential: 3-6                   [1, 64, 56, 56]           36,992\n",
       "│    │    └─SEModule: 3-7                     [1, 64, 56, 56]           8,320\n",
       "│    │    └─ReLU: 3-8                         [1, 64, 56, 56]           --\n",
       "│    └─BasicBlock: 2-5                        [1, 64, 56, 56]           --\n",
       "│    │    └─Sequential: 3-9                   [1, 64, 56, 56]           36,992\n",
       "│    │    └─Sequential: 3-10                  [1, 64, 56, 56]           36,992\n",
       "│    │    └─SEModule: 3-11                    [1, 64, 56, 56]           8,320\n",
       "│    │    └─ReLU: 3-12                        [1, 64, 56, 56]           --\n",
       "├─Sequential: 1-4                             [1, 128, 28, 28]          --\n",
       "│    └─BasicBlock: 2-6                        [1, 128, 28, 28]          --\n",
       "│    │    └─Sequential: 3-13                  [1, 128, 28, 28]          8,448\n",
       "│    │    └─Sequential: 3-14                  [1, 128, 28, 28]          73,984\n",
       "│    │    └─Sequential: 3-15                  [1, 128, 28, 28]          147,712\n",
       "│    │    └─SEModule: 3-16                    [1, 128, 28, 28]          16,576\n",
       "│    │    └─ReLU: 3-17                        [1, 128, 28, 28]          --\n",
       "│    └─BasicBlock: 2-7                        [1, 128, 28, 28]          --\n",
       "│    │    └─Sequential: 3-18                  [1, 128, 28, 28]          147,712\n",
       "│    │    └─Sequential: 3-19                  [1, 128, 28, 28]          147,712\n",
       "│    │    └─SEModule: 3-20                    [1, 128, 28, 28]          16,576\n",
       "│    │    └─ReLU: 3-21                        [1, 128, 28, 28]          --\n",
       "│    └─BasicBlock: 2-8                        [1, 128, 28, 28]          --\n",
       "│    │    └─Sequential: 3-22                  [1, 128, 28, 28]          147,712\n",
       "│    │    └─Sequential: 3-23                  [1, 128, 28, 28]          147,712\n",
       "│    │    └─SEModule: 3-24                    [1, 128, 28, 28]          16,576\n",
       "│    │    └─ReLU: 3-25                        [1, 128, 28, 28]          --\n",
       "│    └─BasicBlock: 2-9                        [1, 128, 28, 28]          --\n",
       "│    │    └─Sequential: 3-26                  [1, 128, 28, 28]          147,712\n",
       "│    │    └─Sequential: 3-27                  [1, 128, 28, 28]          147,712\n",
       "│    │    └─SEModule: 3-28                    [1, 128, 28, 28]          16,576\n",
       "│    │    └─ReLU: 3-29                        [1, 128, 28, 28]          --\n",
       "├─Sequential: 1-5                             [1, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-10                       [1, 1024, 14, 14]         --\n",
       "│    │    └─Sequential: 3-30                  [1, 1024, 14, 14]         133,120\n",
       "│    │    └─Sequential: 3-31                  [1, 256, 28, 28]          33,280\n",
       "│    │    └─Sequential: 3-32                  [1, 256, 14, 14]          590,336\n",
       "│    │    └─SEModule: 3-33                    [1, 256, 14, 14]          65,920\n",
       "│    │    └─Sequential: 3-34                  [1, 1024, 14, 14]         264,192\n",
       "│    │    └─ReLU: 3-35                        [1, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-11                       [1, 1024, 14, 14]         --\n",
       "│    │    └─Sequential: 3-36                  [1, 256, 14, 14]          262,656\n",
       "│    │    └─Sequential: 3-37                  [1, 256, 14, 14]          590,336\n",
       "│    │    └─SEModule: 3-38                    [1, 256, 14, 14]          65,920\n",
       "│    │    └─Sequential: 3-39                  [1, 1024, 14, 14]         264,192\n",
       "│    │    └─ReLU: 3-40                        [1, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-12                       [1, 1024, 14, 14]         --\n",
       "│    │    └─Sequential: 3-41                  [1, 256, 14, 14]          262,656\n",
       "│    │    └─Sequential: 3-42                  [1, 256, 14, 14]          590,336\n",
       "│    │    └─SEModule: 3-43                    [1, 256, 14, 14]          65,920\n",
       "│    │    └─Sequential: 3-44                  [1, 1024, 14, 14]         264,192\n",
       "│    │    └─ReLU: 3-45                        [1, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-13                       [1, 1024, 14, 14]         --\n",
       "│    │    └─Sequential: 3-46                  [1, 256, 14, 14]          262,656\n",
       "│    │    └─Sequential: 3-47                  [1, 256, 14, 14]          590,336\n",
       "│    │    └─SEModule: 3-48                    [1, 256, 14, 14]          65,920\n",
       "│    │    └─Sequential: 3-49                  [1, 1024, 14, 14]         264,192\n",
       "│    │    └─ReLU: 3-50                        [1, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-14                       [1, 1024, 14, 14]         --\n",
       "│    │    └─Sequential: 3-51                  [1, 256, 14, 14]          262,656\n",
       "│    │    └─Sequential: 3-52                  [1, 256, 14, 14]          590,336\n",
       "│    │    └─SEModule: 3-53                    [1, 256, 14, 14]          65,920\n",
       "│    │    └─Sequential: 3-54                  [1, 1024, 14, 14]         264,192\n",
       "│    │    └─ReLU: 3-55                        [1, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-15                       [1, 1024, 14, 14]         --\n",
       "│    │    └─Sequential: 3-56                  [1, 256, 14, 14]          262,656\n",
       "│    │    └─Sequential: 3-57                  [1, 256, 14, 14]          590,336\n",
       "│    │    └─SEModule: 3-58                    [1, 256, 14, 14]          65,920\n",
       "│    │    └─Sequential: 3-59                  [1, 1024, 14, 14]         264,192\n",
       "│    │    └─ReLU: 3-60                        [1, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-16                       [1, 1024, 14, 14]         --\n",
       "│    │    └─Sequential: 3-61                  [1, 256, 14, 14]          262,656\n",
       "│    │    └─Sequential: 3-62                  [1, 256, 14, 14]          590,336\n",
       "│    │    └─SEModule: 3-63                    [1, 256, 14, 14]          65,920\n",
       "│    │    └─Sequential: 3-64                  [1, 1024, 14, 14]         264,192\n",
       "│    │    └─ReLU: 3-65                        [1, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-17                       [1, 1024, 14, 14]         --\n",
       "│    │    └─Sequential: 3-66                  [1, 256, 14, 14]          262,656\n",
       "│    │    └─Sequential: 3-67                  [1, 256, 14, 14]          590,336\n",
       "│    │    └─SEModule: 3-68                    [1, 256, 14, 14]          65,920\n",
       "│    │    └─Sequential: 3-69                  [1, 1024, 14, 14]         264,192\n",
       "│    │    └─ReLU: 3-70                        [1, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-18                       [1, 1024, 14, 14]         --\n",
       "│    │    └─Sequential: 3-71                  [1, 256, 14, 14]          262,656\n",
       "│    │    └─Sequential: 3-72                  [1, 256, 14, 14]          590,336\n",
       "│    │    └─SEModule: 3-73                    [1, 256, 14, 14]          65,920\n",
       "│    │    └─Sequential: 3-74                  [1, 1024, 14, 14]         264,192\n",
       "│    │    └─ReLU: 3-75                        [1, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-19                       [1, 1024, 14, 14]         --\n",
       "│    │    └─Sequential: 3-76                  [1, 256, 14, 14]          262,656\n",
       "│    │    └─Sequential: 3-77                  [1, 256, 14, 14]          590,336\n",
       "│    │    └─SEModule: 3-78                    [1, 256, 14, 14]          65,920\n",
       "│    │    └─Sequential: 3-79                  [1, 1024, 14, 14]         264,192\n",
       "│    │    └─ReLU: 3-80                        [1, 1024, 14, 14]         --\n",
       "│    └─Bottleneck: 2-20                       [1, 1024, 14, 14]         --\n",
       "│    │    └─Sequential: 3-81                  [1, 256, 14, 14]          262,656\n",
       "│    │    └─Sequential: 3-82                  [1, 256, 14, 14]          590,336\n",
       "│    │    └─SEModule: 3-83                    [1, 256, 14, 14]          65,920\n",
       "│    │    └─Sequential: 3-84                  [1, 1024, 14, 14]         264,192\n",
       "│    │    └─ReLU: 3-85                        [1, 1024, 14, 14]         --\n",
       "===============================================================================================\n",
       "Total params: 14,375,296\n",
       "Trainable params: 14,375,296\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 4.58\n",
       "===============================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 102.80\n",
       "Params size (MB): 57.50\n",
       "Estimated Total Size (MB): 160.91\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model.body[:5], input_data=img, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierHead(\n",
       "  (global_pool): SelectAdaptivePool2d (pool_type=fast, flatten=False)\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flattened(nn.Module):\n",
    "    def __init__(self, pretrained_model):\n",
    "        super().__init__()\n",
    "        self.module_list = nn.ModuleList()\n",
    "        self.module_names = []\n",
    "        for name, child in pretrained_model.named_children():\n",
    "            if name == \"_fc\":\n",
    "                continue  # get rid of last layer\n",
    "            if isinstance(child, nn.ModuleList):\n",
    "                for idx, i in enumerate(child):\n",
    "                    self.module_list.append(i)\n",
    "                    self.module_names.append(f\"{name}_{str(idx)}\")\n",
    "            else:\n",
    "                self.module_list.append(child)\n",
    "                self.module_names.append(name)\n",
    "        self._swish_idx = self.module_names.index(\"_swish\")\n",
    "\n",
    "    def forward(self, img_batch):\n",
    "        all_outs = {}\n",
    "        x = img_batch\n",
    "        for idx, module in enumerate(self.module_list):\n",
    "            if self.module_names[idx] == \"_swish\":\n",
    "                continue\n",
    "            elif self.module_names[idx] == \"_dropout\":\n",
    "                shape = x.shape\n",
    "                x = module(x.view(-1, x.shape[1]))\n",
    "            else:\n",
    "                x = module(x)\n",
    "\n",
    "            all_outs[self.module_names[idx]] = x\n",
    "            if \"bn\" in self.module_names[idx]:\n",
    "                x = self.module_list[self._swish_idx](x)\n",
    "        return x, all_outs\n",
    "\n",
    "\n",
    "features = Flattened(eff_net)\n",
    "for name, param in features.named_parameters():\n",
    "    param.requires_grad_(False)\n",
    "#     print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7c78c3tjbE6d"
   },
   "source": [
    "## Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USEhrYiYHLSx"
   },
   "source": [
    "### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 990,
     "status": "ok",
     "timestamp": 1621175027575,
     "user": {
      "displayName": "Isomorphism__",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCPGQv-x0fGHL4DUlrvt2EuQaICcM6lEXnzGpA=s64",
      "userId": "06837884690357263397"
     },
     "user_tz": -600
    },
    "id": "lutFP6pmayNN"
   },
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "        self.tags = set()\n",
    "        self.df_data = pandas.read_csv(TRAIN_CSV_PATH, names=range(4), skiprows=1)\n",
    "        self.df_data[0] = IMG_PATH + \"/\" + self.df_data[0]\n",
    "        self.df_data[3] = self.df_data[3].fillna(\"\")\n",
    "        self.df_data[2] += self.df_data[3]\n",
    "        self.df_data = self.df_data.drop(3, axis=1)\n",
    "        self.df_data = self.df_data.rename({0: \"image\", 1: \"label\", 2: \"caption\"}, axis=1).dropna()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image = PIL.Image.open(self.df_data.iloc[idx, 0])\n",
    "        label = self.df_data.iloc[idx, 1]\n",
    "        caption = self.df_data.iloc[idx, 2]\n",
    "\n",
    "        sample = {\"caption\": caption, \"label\": label, \"image\": image}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPE_x_qeGden"
   },
   "source": [
    "### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 514,
     "status": "ok",
     "timestamp": 1621175027576,
     "user": {
      "displayName": "Isomorphism__",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCPGQv-x0fGHL4DUlrvt2EuQaICcM6lEXnzGpA=s64",
      "userId": "06837884690357263397"
     },
     "user_tz": -600
    },
    "id": "oMHDsQa5pbvJ"
   },
   "outputs": [],
   "source": [
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "        self.tags = set()\n",
    "        self.df_data = pandas.read_csv(TEST_CSV_PATH, names=range(3), skiprows=1)\n",
    "        self.df_data[0] = IMG_PATH + \"/\" + self.df_data[0]\n",
    "        self.df_data[2] = self.df_data[2].fillna(\"\")\n",
    "        self.df_data[1] += self.df_data[2]\n",
    "        self.df_data = self.df_data.drop(2, axis=1)\n",
    "        self.df_data = self.df_data.rename({0: \"image\", 1: \"caption\"}, axis=1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image = PIL.Image.open(self.df_data.iloc[idx, 0])\n",
    "        caption = self.df_data.iloc[idx, 1]\n",
    "\n",
    "        sample = {\"caption\": caption, \"image\": image}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_R5B99nfXD3g"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3scsujfGr18"
   },
   "source": [
    "### Dataset pre-transformations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 781,
     "status": "ok",
     "timestamp": 1621175030901,
     "user": {
      "displayName": "Isomorphism__",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCPGQv-x0fGHL4DUlrvt2EuQaICcM6lEXnzGpA=s64",
      "userId": "06837884690357263397"
     },
     "user_tz": -600
    },
    "id": "zbL0EmlyeNTm"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode_labels(dataset):\n",
    "    if \"one_hot_encoded_labels\" not in dataset.tags:\n",
    "        dataset.df_data[\"label\"] = dataset.df_data[\"label\"].apply(\n",
    "            lambda l: torch.nn.functional.one_hot(\n",
    "                torch.tensor([int(i) - 1 if int(i) < 12 else int(i) - 2 for i in l.split(\" \")]), 18\n",
    "            )\n",
    "            .sum(axis=0)\n",
    "            .float()\n",
    "        )\n",
    "\n",
    "        dataset.tags.add(\"one_hot_encoded_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpTCDn6_Vrco"
   },
   "source": [
    "## Modules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCCA7khCHOnG"
   },
   "source": [
    "### Caption embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ecrmj0tdk78V",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ztan/miniconda3/lib/python3.8/site-packages/torchaudio/backend/utils.py:53: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at prajjwal1/bert-mini were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoFeatureExtractor, AutoModel, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-mini\")\n",
    "lang_model = AutoModel.from_pretrained(\"prajjwal1/bert-mini\")\n",
    "\n",
    "for name, param in lang_model.named_parameters():\n",
    "    param.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vial1naJBNC7"
   },
   "source": [
    "### Pretrained model surgery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6hUrTmdVBj0Q",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b2\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19}\n",
    "# eff_net = EfficientNet.from_pretrained(\"efficientnet-b2\")\n",
    "\n",
    "\n",
    "class Flattened(nn.Module):\n",
    "    def __init__(self, pretrained_model):\n",
    "        super().__init__()\n",
    "        self.module_list = nn.ModuleList()\n",
    "        self.module_names = []\n",
    "        for name, child in pretrained_model.named_children():\n",
    "            if name == \"_fc\":\n",
    "                continue  # get rid of last layer\n",
    "            if isinstance(child, nn.ModuleList):\n",
    "                for idx, i in enumerate(child):\n",
    "                    self.module_list.append(i)\n",
    "                    self.module_names.append(f\"{name}_{str(idx)}\")\n",
    "            else:\n",
    "                self.module_list.append(child)\n",
    "                self.module_names.append(name)\n",
    "        self._swish_idx = self.module_names.index(\"_swish\")\n",
    "\n",
    "    def forward(self, img_batch):\n",
    "        all_outs = {}\n",
    "        x = img_batch\n",
    "        for idx, module in enumerate(self.module_list):\n",
    "            if self.module_names[idx] == \"_swish\":\n",
    "                continue\n",
    "            elif self.module_names[idx] == \"_dropout\":\n",
    "                shape = x.shape\n",
    "                x = module(x.view(-1, x.shape[1]))\n",
    "            else:\n",
    "                x = module(x)\n",
    "\n",
    "            all_outs[self.module_names[idx]] = x\n",
    "            if \"bn\" in self.module_names[idx]:\n",
    "                x = self.module_list[self._swish_idx](x)\n",
    "        return x, all_outs\n",
    "\n",
    "\n",
    "features = Flattened(eff_net)\n",
    "for name, param in features.named_parameters():\n",
    "    param.requires_grad_(False)\n",
    "#     print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1408"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.module_list[-4].weight.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v44fbNqCOtv9"
   },
   "source": [
    "### Combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aUtVf9QdOxnN"
   },
   "outputs": [],
   "source": [
    "NUM_ClASSES = 18\n",
    "import math\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "img_dim = 2048\n",
    "word_dim = list(lang_model.pooler.parameters())[-1].shape[0]\n",
    "\n",
    "\n",
    "class SASGA(nn.Module):\n",
    "    def __init__(self, word_dim=word_dim):\n",
    "        super().__init__()\n",
    "        self.layer_norm_1 = norm = nn.LayerNorm(word_dim, eps=1e-05, elementwise_affine=True)\n",
    "        self.layer_norm_2 = norm = nn.LayerNorm(word_dim, eps=1e-05, elementwise_affine=True)\n",
    "\n",
    "        self.guided_attention_layer = nn.TransformerDecoderLayer(\n",
    "            word_dim, nhead=word_dim // 64, dim_feedforward=word_dim, dropout=0.1, activation=\"relu\"\n",
    "        )\n",
    "        self.guided_attention = nn.TransformerDecoder(\n",
    "            self.guided_attention_layer, num_layers=1, norm=self.layer_norm_1\n",
    "        )\n",
    "        self.self_attention_layer = nn.TransformerDecoderLayer(\n",
    "            word_dim, nhead=word_dim // 64, dim_feedforward=word_dim, dropout=0.1, activation=\"relu\"\n",
    "        )\n",
    "        self.self_attention = nn.TransformerDecoder(\n",
    "            self.self_attention_layer, num_layers=1, norm=self.layer_norm_2\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y, y_mask):\n",
    "        # guide x by y\n",
    "        x = self.self_attention_layer(x, x)\n",
    "        x = self.guided_attention(x, y, memory_key_padding_mask=y_mask)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Combined_Model(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, visual_features, lang_model, word_dim=word_dim, img_dim=img_dim, num_decoder_layers=1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.visual_features = visual_features\n",
    "        self.lang_model = lang_model\n",
    "        self.img_dim = img_dim\n",
    "        self.word_dim = word_dim\n",
    "\n",
    "        self.bottle_neck = nn.Conv2d(in_channels=img_dim, out_channels=word_dim, kernel_size=1)\n",
    "        self.layer_norm = norm = nn.LayerNorm(word_dim, eps=1e-05, elementwise_affine=True)\n",
    "\n",
    "        # SA-GA ##############################\n",
    "        self.SASGA_1 = SASGA(word_dim)\n",
    "        self.SASGA_2 = SASGA(word_dim)\n",
    "        self.SASGA_3 = SASGA(word_dim)\n",
    "        # SA-GA ##############################\n",
    "\n",
    "        self.output = nn.Linear(word_dim, NUM_ClASSES)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.proj_all = nn.Linear(word_dim * 2, word_dim)\n",
    "\n",
    "    def forward(self, images, inputs):  # requires tokenized captions\n",
    "        lang_outs = self.lang_model(**inputs)\n",
    "        last_hidden_state = lang_outs[\"last_hidden_state\"].permute(1, 0, 2)  # seq_len,\n",
    "        pooler_out = lang_outs[\"pooler_output\"]\n",
    "        mask = inputs.attention_mask == 0\n",
    "\n",
    "        images, intermediate_outputs = self.visual_features(images)\n",
    "        image_query = intermediate_outputs[\"_conv_head\"]\n",
    "        image_query = self.bottle_neck(image_query)\n",
    "\n",
    "        # no param attention:\n",
    "        #         image_query = image_query.view(-1, self.word_dim, 49)\n",
    "        #         last_hidden_state = lang_outs[\"last_hidden_state\"] # batch, seq_len, word_dim\n",
    "\n",
    "        #         attention_weights = torch.bmm(last_hidden_state, image_query) # batch, seq_len, 49\n",
    "        #         att_out = torch.bmm(attention_weights.permute(0,2,1), last_hidden_state).mean(1)\n",
    "        #         att_out = self.layer_norm(att_out+image_query.mean(-1))\n",
    "\n",
    "        #####################################################\n",
    "        # self attention\n",
    "        # image_query = image_query.view(-1, self.word_dim, 49).permute(2, 0, 1)\n",
    "        # att_out = self.self_attention_layer(image_query, image_query)\n",
    "\n",
    "        # #         # guided attention\n",
    "        # att_out = self.guided_attention(att_out, last_hidden_state, memory_key_padding_mask=mask)\n",
    "        # att_out = att_out.permute(1, 2, 0)  # 49, batch, word_dim -> batch, word_dim, 49\n",
    "        # att_out = att_out.mean(-1)  # -> batch, word_dim\n",
    "        #####################################################\n",
    "        image_query_1 = image_query.view(-1, self.word_dim, 49).permute(2, 0, 1)\n",
    "        image_query_2 = image_query.view(-1, 49, self.word_dim).permute(1, 0, 2)\n",
    "        assert (image_query_1 != image_query_2).any()\n",
    "        att_1 = self.SASGA_1(image_query_1, last_hidden_state, mask)\n",
    "        att_2 = self.SASGA_2(image_query_2, last_hidden_state, mask)\n",
    "        att_3 = self.layer_norm(att_1 + att_2)\n",
    "        att_out = self.SASGA_3(att_3, last_hidden_state, mask).permute(1, 2, 0).mean(-1)\n",
    "\n",
    "        out = torch.cat([att_out, pooler_out], dim=-1)\n",
    "        out = self.proj_all(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.output(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for name, _ in model.module_list.named_parameters():\n",
    "#     print(name, _.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srZFInwa78_j"
   },
   "source": [
    "## Transforms and training support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 772,
     "status": "ok",
     "timestamp": 1621175053522,
     "user": {
      "displayName": "Isomorphism__",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCPGQv-x0fGHL4DUlrvt2EuQaICcM6lEXnzGpA=s64",
      "userId": "06837884690357263397"
     },
     "user_tz": -600
    },
    "id": "MvOT-Plt78Zp"
   },
   "outputs": [],
   "source": [
    "class FieldTransform(object):\n",
    "    def __init__(self, field, transform):\n",
    "        self.field = field\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sample[self.field] = self.transform(sample[self.field])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZHM_qQiQniU"
   },
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 771,
     "status": "ok",
     "timestamp": 1621175053523,
     "user": {
      "displayName": "Isomorphism__",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCPGQv-x0fGHL4DUlrvt2EuQaICcM6lEXnzGpA=s64",
      "userId": "06837884690357263397"
     },
     "user_tz": -600
    },
    "id": "oPqavf7wWfiB"
   },
   "outputs": [],
   "source": [
    "def train_collate_fn(X):\n",
    "    # convert [{key: val, ...}, ...]\n",
    "    # to [key: [val, ...],  ...}\n",
    "    X = {k: [v[k] for v in X] for k in X[0]}\n",
    "    X[\"label\"] = torch.stack(X[\"label\"])\n",
    "    X[\"image\"] = torch.stack(X[\"image\"])\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        FieldTransform(\"image\", torchvision.transforms.Resize((256, 256))),\n",
    "        FieldTransform(\"image\", torchvision.transforms.ToTensor()),\n",
    "        FieldTransform(\"image\", normalize),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 2421,
     "status": "ok",
     "timestamp": 1621175110701,
     "user": {
      "displayName": "Isomorphism__",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjCPGQv-x0fGHL4DUlrvt2EuQaICcM6lEXnzGpA=s64",
      "userId": "06837884690357263397"
     },
     "user_tz": -600
    },
    "id": "o_5acvhCWjSn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = TrainDataset(transform=transforms)\n",
    "# vocabularise_caption(train_data, vocab)\n",
    "one_hot_encode_labels(train_data)\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# train_data.__len__() == 30000\n",
    "trainds, valds = random_split(train_data, [27000, 3000])\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    trainds, batch_size=32, shuffle=True, collate_fn=train_collate_fn, num_workers=24\n",
    ")\n",
    "\n",
    "val_dl = DataLoader(valds, batch_size=8, shuffle=False, collate_fn=train_collate_fn, num_workers=24)\n",
    "\n",
    "# model = Combined().to(DEVICE)\n",
    "\n",
    "\n",
    "# model = Combined_Model(features, lang_model, num_decoder_layers=1).to(device)\n",
    "\n",
    "\n",
    "from sam import SAM\n",
    "\n",
    "base_optimizer = torch.optim.Adam  # define an optimizer for the \"sharpness-aware\" update\n",
    "optimizer = SAM(model.parameters(), base_optimizer, lr=5e-5)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    threshold=0.0001,\n",
    "    threshold_mode=\"rel\",\n",
    "    cooldown=5,\n",
    "    min_lr=0,\n",
    "    eps=1e-08,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for name, param in model.module_list.named_parameters():\n",
    "#     print(name)\n",
    "# raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, \"test_v8.pt\") #check model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iuhLuCQxQnR1",
    "outputId": "bde8bc1d-7820-460e-8d89-e78e8af216d4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/844 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-3e21bccca881>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "\n",
    "val_mean_f1 = []\n",
    "val_sample_f1 = []\n",
    "model_in_memory = {}\n",
    "\n",
    "# scaler = torch.cuda.amp.GradScaler()\n",
    "for epoch in range(50):\n",
    "    train_loss = []\n",
    "    train_outs = []\n",
    "    train_lables = []\n",
    "    #     model.train()\n",
    "\n",
    "    #     fine tune CNN for 5 epoches\n",
    "    #     if epoch == 0:\n",
    "    #         finetune_param = False\n",
    "    #         for name, param in model.visual_features.module_list.named_parameters():\n",
    "    #             if \"21\" in name.split(\".\"):  # or 21, required grad for after the attentions\n",
    "    #                 finetune_param = True\n",
    "    #             if finetune_param:\n",
    "    #                 print(name)\n",
    "    #                 param.requires_grad_(True)\n",
    "\n",
    "    #     if epoch == 0:\n",
    "    #         finetune_param = False\n",
    "    #         for name, param in model.lang_model.named_parameters():\n",
    "    #             if \"3\" in name:\n",
    "    #                 finetune_param = True\n",
    "    #             if finetune_param:\n",
    "    #                 print(name)\n",
    "    #                 param.requires_grad_(True)\n",
    "\n",
    "    for i, batch in enumerate(tqdm(train_dl)):\n",
    "        optimizer.zero_grad()\n",
    "        captions = batch[\"caption\"]\n",
    "        images = batch[\"image\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "        inputs = tokenizer(captions, return_tensors=\"pt\", padding=True, truncation=False).to(device)\n",
    "\n",
    "        raise ValueError\n",
    "\n",
    "        #         with torch.cuda.amp.autocast():\n",
    "        # first second step\n",
    "        predictions = model(images, inputs)\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        #         optimizer.step()\n",
    "        optimizer.first_step(zero_grad=True)\n",
    "\n",
    "        #         with torch.cuda.amp.autocast():\n",
    "        # second step\n",
    "        predictions = model(images, inputs)\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "        #\n",
    "        #         scaler.scale(loss).backward()\n",
    "        #         scaler.step(optim)\n",
    "        #         scaler.update()\n",
    "        #         train_loss.append(scaled_loss.item())\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "    val_loss = []\n",
    "    val_outs = []\n",
    "    val_labels = []\n",
    "\n",
    "    model.eval()\n",
    "    for i, batch in enumerate(val_dl):\n",
    "\n",
    "        captions = batch[\"caption\"]\n",
    "        images = batch[\"image\"].to(DEVICE)\n",
    "        labels = batch[\"label\"].to(DEVICE)\n",
    "        inputs = tokenizer(captions, return_tensors=\"pt\", padding=True, truncation=False).to(device)\n",
    "\n",
    "        #         predictions = model(images, captions)\n",
    "        #         with torch.cuda.amp.autocast():\n",
    "        predictions = model(images, inputs)\n",
    "        loss = criterion(predictions, labels)\n",
    "        val_loss.append(loss.item())\n",
    "        val_outs.append(predictions.detach().cpu().numpy())\n",
    "        val_labels.append(labels.detach().cpu().numpy())\n",
    "    val_labels = np.vstack(val_labels)\n",
    "    val_outs = np.vstack(val_outs)\n",
    "    mean_f1 = f1_score(y_true=val_labels, y_pred=1 * (val_outs > 0), average=\"micro\")  # mean f1\n",
    "    sample_f1 = f1_score(y_true=val_labels, y_pred=1 * (val_outs > 0), average=\"samples\")  # mean f1\n",
    "\n",
    "    cur_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    print(\n",
    "        f\"Epoch:{epoch}, train/val loss:{round(np.mean(train_loss),7),round(np.mean(val_loss),7)},sample/mean f1:{round(sample_f1, 7), round(mean_f1, 7)}, lr:{cur_lr}\"\n",
    "    )\n",
    "    scheduler.step(np.mean(val_loss))\n",
    "\n",
    "    if len(val_sample_f1) == 0 or sample_f1 > max(val_sample_f1):\n",
    "        print(\"saving best\")\n",
    "        try:\n",
    "            del model_in_memory[\"best\"]\n",
    "        except:\n",
    "            pass\n",
    "        torch.cuda.empty_cache()\n",
    "        model.to(\"cpu\")\n",
    "        model_in_memory[\"best\"] = deepcopy(model.state_dict())\n",
    "        model.to(device)\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(model_in_memory[\"best\"], \"test_v8.pt\")\n",
    "\n",
    "    val_mean_f1.append(mean_f1)\n",
    "    val_sample_f1.append(sample_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError\n",
    "# (finetune last 3 layer (15-17)) + (SAM, lr 0.001)\n",
    "# b0 + bert tiny + no attention = 85\n",
    "# b0 + bert tiny + SAGA * 1 = 85 ...\n",
    "# b0 + bert tiny + bmm (attention but no weights) at last conv filters = fails..?! (lr too high )\n",
    "# b0 (13-) + bert tiny + bmm (attention but no weights) = 85\n",
    "# b0 + bert tiny (both no finetune) + SAGA * 1 (5e-5 lr)= 86.40\n",
    "# b2 + bert mini (both no finetune) + SAGA * 1 (5e-5 lr)= 86.3\n",
    "# b2 + bert mini (finetune from 21/3 attention) + SAGA * 1 (5e-5 lr)= 87.4.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = lang_model(**inputs)\n",
    "last_hidden_state = outs.last_hidden_state\n",
    "pooler_output = outs.pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_feats, all_outs = features(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outs[\"_conv_head\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.shape, last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bottle_neck = nn.Conv2d(in_channels=1408, out_channels=256, kernel_size=1).to(device)\n",
    "norm = nn.LayerNorm(256, eps=1e-05, elementwise_affine=True)\n",
    "decoder_layer = nn.TransformerDecoderLayer(\n",
    "    256, 8, dim_feedforward=1024, dropout=0.1, activation=\"relu\"\n",
    ")\n",
    "decoder = nn.TransformerDecoder(decoder_layer, num_layers=1, norm=norm).to(device)\n",
    "\n",
    "comp = bottle_neck(all_outs[\"_conv_head\"]).view(-1, 256, 49).permute(2, 0, 1)\n",
    "decoder(comp, last_hidden_state, memory_key_padding_mask=(inputs.attention_mask == 0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "images = torch.randn(1, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "eff_net = EfficientNet.from_pretrained(\"efficientnet-b2\")\n",
    "\n",
    "for name, param in eff_net.named_parameters():\n",
    "    param.requires_grad_(False)\n",
    "\n",
    "\n",
    "class Flattened(nn.Module):\n",
    "    def __init__(self, pretrained_model):\n",
    "        super().__init__()\n",
    "        self.module_list = nn.ModuleList()\n",
    "        self.module_names = []\n",
    "        for name, child in pretrained_model.named_children():\n",
    "            if name == \"_fc\":\n",
    "                continue  # get rid of last layer\n",
    "            if isinstance(child, nn.ModuleList):\n",
    "                for idx, i in enumerate(child):\n",
    "                    self.module_list.append(i)\n",
    "                    self.module_names.append(f\"{name}_{str(idx)}\")\n",
    "            else:\n",
    "                self.module_list.append(child)\n",
    "                self.module_names.append(name)\n",
    "        self._swish_idx = self.module_names.index(\"_swish\")\n",
    "\n",
    "    def forward(self, img_batch):\n",
    "        all_outs = {}\n",
    "        x = img_batch\n",
    "        for idx, module in enumerate(self.module_list):\n",
    "            if self.module_names[idx] == \"_swish\":\n",
    "                continue\n",
    "            elif self.module_names[idx] == \"_dropout\":\n",
    "                shape = x.shape\n",
    "                x = module(x.view(-1, x.shape[1]))\n",
    "            else:\n",
    "                x = module(x)\n",
    "\n",
    "            all_outs[self.module_names[idx]] = x\n",
    "            if \"bn\" in self.module_names[idx]:\n",
    "                x = self.module_list[self._swish_idx](x)\n",
    "        return x, all_outs\n",
    "\n",
    "\n",
    "eff_net.eval()\n",
    "eff_net\n",
    "f = Flattened(eff_net)\n",
    "x, all_outs = f(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "activation = {}\n",
    "\n",
    "\n",
    "def get_activation(name):\n",
    "    def hook(eff_net, input, output):\n",
    "        activation[name] = output\n",
    "\n",
    "    return hook\n",
    "\n",
    "\n",
    "for name, child in eff_net.named_children():\n",
    "    if isinstance(child, nn.ModuleList):\n",
    "        for idx, i in enumerate(child):\n",
    "            i.register_forward_hook(get_activation(f\"{name}_{str(idx)}\"))\n",
    "    else:\n",
    "        child.register_forward_hook(get_activation(name))\n",
    "\n",
    "\n",
    "output = eff_net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key in activation.keys():\n",
    "    if key == \"_swish\":\n",
    "        continue\n",
    "    print(key)\n",
    "    print((all_outs[key] == activation[key]).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# eff_net.to(\"cuda\")\n",
    "# f.to(\"cuda\")\n",
    "\n",
    "# %timeit -n10 -r5 eff_net(images.cuda())\n",
    "# %timeit -n10 -r5 f(images.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "batch_size = 1\n",
    "summary(f, input_size=(batch_size, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for k, v in all_outs.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "208 * 3 + 352 * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from effdet import create_model\n",
    "\n",
    "model = create_model(\"tf_efficientdet_d0\", bench_task=\"predict\", num_classes=18, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.cpu()\n",
    "labels = labels.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type:depth-idx)                                                 Output Shape              Param #\n",
       "========================================================================================================================\n",
       "EfficientDet                                                           --                        --\n",
       "├─EfficientNetFeatures: 1-1                                            [32, 40, 32, 32]          --\n",
       "│    └─Conv2dSame: 2-1                                                 [32, 32, 128, 128]        864\n",
       "│    └─BatchNorm2d: 2-2                                                [32, 32, 128, 128]        64\n",
       "│    └─SiLU: 2-3                                                       [32, 32, 128, 128]        --\n",
       "│    └─Sequential: 2                                                   --                        --\n",
       "│    │    └─Sequential: 3-1                                            [32, 16, 128, 128]        1,448\n",
       "│    │    └─Sequential: 3-2                                            [32, 24, 64, 64]          16,714\n",
       "│    │    └─Sequential: 3-3                                            [32, 40, 32, 32]          46,640\n",
       "│    │    └─Sequential: 3-4                                            [32, 80, 16, 16]          242,930\n",
       "│    │    └─Sequential: 3-5                                            [32, 112, 16, 16]         543,148\n",
       "│    │    └─Sequential: 3-6                                            [32, 192, 8, 8]           2,026,348\n",
       "│    │    └─Sequential: 3-7                                            [32, 320, 8, 8]           717,232\n",
       "├─BiFpn: 1-2                                                           [32, 64, 32, 32]          --\n",
       "│    └─ModuleDict: 2                                                   --                        --\n",
       "│    │    └─ResampleFeatureMap: 3-8                                    [32, 64, 4, 4]            20,672\n",
       "│    │    └─ResampleFeatureMap: 3-9                                    [32, 64, 2, 2]            --\n",
       "│    └─SequentialList: 2-4                                             [32, 64, 32, 32]          --\n",
       "│    │    └─BiFpnLayer: 3-10                                           [32, 64, 32, 32]          97,747\n",
       "│    │    └─BiFpnLayer: 3-11                                           [32, 64, 32, 32]          38,931\n",
       "│    │    └─BiFpnLayer: 3-12                                           [32, 64, 32, 32]          38,931\n",
       "├─HeadNet: 1-3                                                         [32, 162, 32, 32]         --\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-13                                      [32, 64, 32, 32]          4,736\n",
       "│    └─SiLU: 2-5                                                       [32, 64, 32, 32]          --\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-14                                      [32, 64, 32, 32]          4,736\n",
       "│    └─SiLU: 2-6                                                       [32, 64, 32, 32]          --\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-15                                      [32, 64, 32, 32]          4,736\n",
       "│    └─SiLU: 2-7                                                       [32, 64, 32, 32]          --\n",
       "│    └─SeparableConv2d: 2-8                                            [32, 162, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-16                                               [32, 64, 32, 32]          576\n",
       "│    │    └─Conv2d: 3-17                                               [32, 162, 32, 32]         10,530\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-18                                      [32, 64, 16, 16]          (recursive)\n",
       "│    └─SiLU: 2-9                                                       [32, 64, 16, 16]          --\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-19                                      [32, 64, 16, 16]          (recursive)\n",
       "│    └─SiLU: 2-10                                                      [32, 64, 16, 16]          --\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-20                                      [32, 64, 16, 16]          (recursive)\n",
       "│    └─SiLU: 2-11                                                      [32, 64, 16, 16]          --\n",
       "│    └─SeparableConv2d: 2-12                                           [32, 162, 16, 16]         (recursive)\n",
       "│    │    └─Conv2d: 3-21                                               [32, 64, 16, 16]          (recursive)\n",
       "│    │    └─Conv2d: 3-22                                               [32, 162, 16, 16]         (recursive)\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-23                                      [32, 64, 8, 8]            (recursive)\n",
       "│    └─SiLU: 2-13                                                      [32, 64, 8, 8]            --\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-24                                      [32, 64, 8, 8]            (recursive)\n",
       "│    └─SiLU: 2-14                                                      [32, 64, 8, 8]            --\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-25                                      [32, 64, 8, 8]            (recursive)\n",
       "│    └─SiLU: 2-15                                                      [32, 64, 8, 8]            --\n",
       "│    └─SeparableConv2d: 2-16                                           [32, 162, 8, 8]           (recursive)\n",
       "│    │    └─Conv2d: 3-26                                               [32, 64, 8, 8]            (recursive)\n",
       "│    │    └─Conv2d: 3-27                                               [32, 162, 8, 8]           (recursive)\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-28                                      [32, 64, 4, 4]            (recursive)\n",
       "│    └─SiLU: 2-17                                                      [32, 64, 4, 4]            --\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-29                                      [32, 64, 4, 4]            (recursive)\n",
       "│    └─SiLU: 2-18                                                      [32, 64, 4, 4]            --\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-30                                      [32, 64, 4, 4]            (recursive)\n",
       "│    └─SiLU: 2-19                                                      [32, 64, 4, 4]            --\n",
       "│    └─SeparableConv2d: 2-20                                           [32, 162, 4, 4]           (recursive)\n",
       "│    │    └─Conv2d: 3-31                                               [32, 64, 4, 4]            (recursive)\n",
       "│    │    └─Conv2d: 3-32                                               [32, 162, 4, 4]           (recursive)\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-33                                      [32, 64, 2, 2]            (recursive)\n",
       "│    └─SiLU: 2-21                                                      [32, 64, 2, 2]            --\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-34                                      [32, 64, 2, 2]            (recursive)\n",
       "│    └─SiLU: 2-22                                                      [32, 64, 2, 2]            --\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-35                                      [32, 64, 2, 2]            (recursive)\n",
       "│    └─SiLU: 2-23                                                      [32, 64, 2, 2]            --\n",
       "│    └─SeparableConv2d: 2-24                                           [32, 162, 2, 2]           (recursive)\n",
       "│    │    └─Conv2d: 3-36                                               [32, 64, 2, 2]            (recursive)\n",
       "│    │    └─Conv2d: 3-37                                               [32, 162, 2, 2]           (recursive)\n",
       "├─HeadNet: 1-4                                                         [32, 36, 32, 32]          --\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-38                                      [32, 64, 32, 32]          4,736\n",
       "│    └─SiLU: 2-25                                                      [32, 64, 32, 32]          --\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-39                                      [32, 64, 32, 32]          4,736\n",
       "│    └─SiLU: 2-26                                                      [32, 64, 32, 32]          --\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-40                                      [32, 64, 32, 32]          4,736\n",
       "│    └─SiLU: 2-27                                                      [32, 64, 32, 32]          --\n",
       "│    └─SeparableConv2d: 2-28                                           [32, 36, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-41                                               [32, 64, 32, 32]          576\n",
       "│    │    └─Conv2d: 3-42                                               [32, 36, 32, 32]          2,340\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-43                                      [32, 64, 16, 16]          (recursive)\n",
       "│    └─SiLU: 2-29                                                      [32, 64, 16, 16]          --\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-44                                      [32, 64, 16, 16]          (recursive)\n",
       "│    └─SiLU: 2-30                                                      [32, 64, 16, 16]          --\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-45                                      [32, 64, 16, 16]          (recursive)\n",
       "│    └─SiLU: 2-31                                                      [32, 64, 16, 16]          --\n",
       "│    └─SeparableConv2d: 2-32                                           [32, 36, 16, 16]          (recursive)\n",
       "│    │    └─Conv2d: 3-46                                               [32, 64, 16, 16]          (recursive)\n",
       "│    │    └─Conv2d: 3-47                                               [32, 36, 16, 16]          (recursive)\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-48                                      [32, 64, 8, 8]            (recursive)\n",
       "│    └─SiLU: 2-33                                                      [32, 64, 8, 8]            --\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-49                                      [32, 64, 8, 8]            (recursive)\n",
       "│    └─SiLU: 2-34                                                      [32, 64, 8, 8]            --\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-50                                      [32, 64, 8, 8]            (recursive)\n",
       "│    └─SiLU: 2-35                                                      [32, 64, 8, 8]            --\n",
       "│    └─SeparableConv2d: 2-36                                           [32, 36, 8, 8]            (recursive)\n",
       "│    │    └─Conv2d: 3-51                                               [32, 64, 8, 8]            (recursive)\n",
       "│    │    └─Conv2d: 3-52                                               [32, 36, 8, 8]            (recursive)\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-53                                      [32, 64, 4, 4]            (recursive)\n",
       "│    └─SiLU: 2-37                                                      [32, 64, 4, 4]            --\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-54                                      [32, 64, 4, 4]            (recursive)\n",
       "│    └─SiLU: 2-38                                                      [32, 64, 4, 4]            --\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-55                                      [32, 64, 4, 4]            (recursive)\n",
       "│    └─SiLU: 2-39                                                      [32, 64, 4, 4]            --\n",
       "│    └─SeparableConv2d: 2-40                                           [32, 36, 4, 4]            (recursive)\n",
       "│    │    └─Conv2d: 3-56                                               [32, 64, 4, 4]            (recursive)\n",
       "│    │    └─Conv2d: 3-57                                               [32, 36, 4, 4]            (recursive)\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-58                                      [32, 64, 2, 2]            (recursive)\n",
       "│    └─SiLU: 2-41                                                      [32, 64, 2, 2]            --\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-59                                      [32, 64, 2, 2]            (recursive)\n",
       "│    └─SiLU: 2-42                                                      [32, 64, 2, 2]            --\n",
       "│    └─ModuleList: 2                                                   --                        --\n",
       "│    │    └─SeparableConv2d: 3-60                                      [32, 64, 2, 2]            (recursive)\n",
       "│    └─SiLU: 2-43                                                      [32, 64, 2, 2]            --\n",
       "│    └─SeparableConv2d: 2-44                                           [32, 36, 2, 2]            (recursive)\n",
       "│    │    └─Conv2d: 3-61                                               [32, 64, 2, 2]            (recursive)\n",
       "│    │    └─Conv2d: 3-62                                               [32, 36, 2, 2]            (recursive)\n",
       "========================================================================================================================\n",
       "Total params: 3,834,107\n",
       "Trainable params: 3,834,107\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 18.18\n",
       "========================================================================================================================\n",
       "Input size (MB): 25.17\n",
       "Forward/backward pass size (MB): 5194.35\n",
       "Params size (MB): 15.34\n",
       "Estimated Total Size (MB): 5234.85\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model.model, input_data=images, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model.model.backbone(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 36, 32, 32])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNetFeatures(\n",
       "  (conv_stem): Conv2dSame(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): SiLU(inplace=True)\n",
       "  (blocks): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2dSame(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
       "        (bn2): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2dSame(144, 144, kernel_size=(5, 5), stride=(2, 2), groups=144, bias=False)\n",
       "        (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "        (bn2): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2dSame(240, 240, kernel_size=(3, 3), stride=(2, 2), groups=240, bias=False)\n",
       "        (bn2): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (bn2): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (bn2): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "        (bn2): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2dSame(672, 672, kernel_size=(5, 5), stride=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_name = \"test.pt\"\n",
    "# model = LUKE_CRF(tag_to_ix, lang_model=lang_model, hidden_dim=1024)\n",
    "model = Combined_Model(features, lang_model)\n",
    "model.load_state_dict(torch.load(\"test.pt\"))\n",
    "model.to(device)\n",
    "# model = torch.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "\n",
    "# model = torch.load(model_name)\n",
    "# # use the same validation set/training set\n",
    "# val_outs = []\n",
    "# val_labels = []\n",
    "# model.eval()\n",
    "# for i, batch in enumerate(val_dl):\n",
    "\n",
    "#     captions = batch[\"caption\"]\n",
    "#     images = batch[\"image\"].to(DEVICE)\n",
    "#     labels = batch[\"label\"].to(DEVICE)\n",
    "\n",
    "#     inputs = tokenizer(captions, return_tensors=\"pt\", padding=True, truncation=False)\n",
    "#     input_ids = inputs[\"input_ids\"].to(device)\n",
    "#     attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "\n",
    "#     # predictions = model(images, captions)\n",
    "#     predictions = model(images, input_ids, attention_mask)\n",
    "\n",
    "#     val_outs.append(predictions.detach().cpu().numpy())\n",
    "#     val_labels.append(labels.detach().cpu().numpy())\n",
    "# val_labels = np.vstack(val_labels)\n",
    "# val_outs = np.vstack(val_outs)\n",
    "\n",
    "# best_thresholds = np.zeros(18)\n",
    "# for i in range(18):\n",
    "#     fpr, tpr, thresholds = roc_curve(val_labels[:, i], (val_outs)[:, i])\n",
    "#     gmeans = np.sqrt(tpr * (1 - fpr))\n",
    "#     ix = np.argmax(gmeans)\n",
    "#     best_thresholds[i] = thresholds[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cheat\n",
    "class CheatDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "        self.tags = set()\n",
    "        self.df_data = pd.read_csv(\"test_cheat.csv\", names=range(3), skiprows=1)[[0, 2, 1]].dropna()\n",
    "        self.df_data[0] = IMG_PATH + \"/\" + self.df_data[0]\n",
    "        self.df_data = self.df_data.rename({0: \"image\", 2: \"label\", 1: \"caption\"}, axis=1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image = PIL.Image.open(self.df_data.iloc[idx, 0])\n",
    "        label = self.df_data.iloc[idx, 1]\n",
    "        caption = self.df_data.iloc[idx, 2]\n",
    "\n",
    "        sample = {\"caption\": caption, \"label\": label, \"image\": image}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "cheat_data = CheatDataset(transform=transforms)\n",
    "# vocabularise_caption(train_data, vocab)\n",
    "one_hot_encode_labels(cheat_data)\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# train_data.__len__() == 30000\n",
    "cheat_dl = DataLoader(\n",
    "    cheat_data, batch_size=32, shuffle=False, collate_fn=train_collate_fn, num_workers=24\n",
    ")\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# use the same validation set/training set\n",
    "val_outs = []\n",
    "val_labels = []\n",
    "model.eval()\n",
    "for i, batch in enumerate(cheat_dl):\n",
    "\n",
    "    captions = batch[\"caption\"]\n",
    "    images = batch[\"image\"].to(device)\n",
    "    labels = batch[\"label\"].to(device)\n",
    "    inputs = tokenizer(captions, return_tensors=\"pt\", padding=True, truncation=False).to(device)\n",
    "\n",
    "    # predictions = model(images, captions)\n",
    "    predictions = model(images, inputs)\n",
    "\n",
    "    val_outs.append(predictions.detach().cpu().numpy())\n",
    "    val_labels.append(labels.detach().cpu().numpy())\n",
    "val_labels = np.vstack(val_labels)\n",
    "val_outs = np.vstack(val_outs)\n",
    "\n",
    "\n",
    "best_thresholds = np.zeros(18)\n",
    "for i in range(18):\n",
    "    fpr, tpr, thresholds = precision, recall, thresholds = precision_recall_curve(\n",
    "        val_labels[:, i], (val_outs)[:, i]\n",
    "    )\n",
    "    fscore = (2 * precision * recall) / (precision + recall)\n",
    "    # locate the index of the largest f score\n",
    "    ix = np.argmax(fscore)\n",
    "    best_thresholds[i] = thresholds[ix]\n",
    "\n",
    "print(best_thresholds)\n",
    "np.save(\"best_thresholds\", best_thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopper for run all\n",
    "raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_collate_fn(X):\n",
    "    # convert [{key: val, ...}, ...]\n",
    "    # to [key: [val, ...],  ...}\n",
    "    X = {k: [v[k] for v in X] for k in X[0]}\n",
    "    X[\"image\"] = torch.stack(X[\"image\"])\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "test_data = TestDataset(transform=transforms)\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=16, shuffle=False, collate_fn=test_collate_fn, num_workers=0,\n",
    ")\n",
    "\n",
    "\n",
    "# save predictions\n",
    "model.eval()\n",
    "test_preds = []\n",
    "for i, batch in enumerate(test_dl):\n",
    "    captions = batch[\"caption\"]\n",
    "    inputs = tokenizer(captions, return_tensors=\"pt\", padding=True, truncation=False).to(device)\n",
    "\n",
    "    predictions = model(images, inputs)\n",
    "    test_preds.append(predictions.detach().cpu().numpy())\n",
    "\n",
    "test_preds = np.vstack(test_preds)\n",
    "\n",
    "\n",
    "def out_logits_to_preds(logits, best_thresholds):\n",
    "    labels = []\n",
    "    logits = (logits - np.zeros_like(best_thresholds)) > 0\n",
    "    lables_available = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19])\n",
    "    for i in range(logits.shape[0]):\n",
    "        labels.append(list(lables_available[logits[i]]))\n",
    "    return labels\n",
    "\n",
    "\n",
    "# lables_available[(test_preds[:10] > 0)]\n",
    "# {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19}\n",
    "\n",
    "test_labels = out_logits_to_preds(test_preds, best_thresholds)\n",
    "\n",
    "df_test = pd.read_csv(TEST_CSV_PATH, names=range(3), skiprows=1)\n",
    "test_labels_str = [\" \".join([str(i) for i in labels]) for labels in test_labels]\n",
    "df_test[\"Labels\"] = test_labels_str\n",
    "df_test.rename({0: \"ImageID\"}, axis=1, inplace=True)\n",
    "\n",
    "df_test[[\"ImageID\", \"Labels\"]].to_csv(\"test_predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "COMP5329_Assignment_2_v3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "105bdd467ce44751b3020eddd3d4c791": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37766d0f97754f21a9b78ec7c2c9b266": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b5faf89e145490b8df3c5a0974a30e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37766d0f97754f21a9b78ec7c2c9b266",
      "max": 21388428,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a0e1d4db2eb74c24887d9b9d63e36a2a",
      "value": 21388428
     }
    },
    "6c592ed619724f1997199bf45b9727e7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "775c2d8bc3824da89165a6baf24327c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3b5faf89e145490b8df3c5a0974a30e0",
       "IPY_MODEL_fbc0ba310f384411ad658bc8ceee5607"
      ],
      "layout": "IPY_MODEL_6c592ed619724f1997199bf45b9727e7"
     }
    },
    "9929ab1374f74db7addc12be1eaa6a29": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0e1d4db2eb74c24887d9b9d63e36a2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fbc0ba310f384411ad658bc8ceee5607": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_105bdd467ce44751b3020eddd3d4c791",
      "placeholder": "​",
      "style": "IPY_MODEL_9929ab1374f74db7addc12be1eaa6a29",
      "value": " 20.4M/20.4M [00:00&lt;00:00, 70.0MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
